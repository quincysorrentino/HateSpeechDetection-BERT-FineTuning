{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load directly from Hugging Face Hub by its dataset identifier\n",
    "hate_explain = load_dataset(\"Abhi0072/HateXplain\")\n",
    "\n",
    "# convert to dataframe\n",
    "hate_explain = hate_explain['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621851c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_explain.info()\n",
    "hate_explain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3894028",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"normal\": 2,\n",
    "    \"hatespeech\": 0,\n",
    "    \"offensive\": 1\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the mapping to the label column\n",
    "hate_explain['label'] = hate_explain['label'].apply(lambda label: label_mapping.get(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc34bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_explain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_dataset = load_dataset(\"tdavidson/hate_speech_offensive\")\n",
    "# convert to dataframe\n",
    "davidson_df = davidson_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'class' column to 'label'\n",
    "davidson_df = davidson_df.rename(columns={'class': 'label', 'tweet': 'text'})\n",
    "davidson_df = davidson_df.drop(columns=[\"neither_count\", \"offensive_language_count\", \"hate_speech_count\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "gab = load_dataset(\"juliadollis/The_Gab_Hate_Corpus_ghc_train_original\")\n",
    "# convert to dataframe\n",
    "gab = gab['train'].to_pandas()\n",
    "\n",
    "# Filter hate speech (either attacks dignity or calls for violence)\n",
    "gab_hate = gab[(gab[\"hd\"] == 1) | (gab[\"cv\"] == 1)].copy()\n",
    "\n",
    "gab_hate['label'] = 0\n",
    "gab_hate = gab_hate.drop(columns=[\"hd\", \"cv\", \"vo\"])\n",
    "\n",
    "\n",
    "# Filter only offensive speech (vulgar but not hateful)\n",
    "gab_offensive = gab[(gab[\"vo\"] == 1) & (gab[\"hd\"] == 0) & (gab[\"cv\"] == 0)].copy()\n",
    "\n",
    "gab_offensive['label'] = 1\n",
    "gab_offensive = gab_offensive.drop(columns=[\"hd\", \"cv\", \"vo\"])\n",
    "gab_offensive.head()\n",
    "\n",
    "gab = pd.concat([gab_hate, gab_offensive])\n",
    "\n",
    "gab.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "frankshu = load_dataset(\"thefrankhsu/hate_speech_twitter\")\n",
    "# convert to dataframe\n",
    "frankshu = frankshu['train'].to_pandas()\n",
    "\n",
    "frankshu_hate = frankshu[frankshu['label'] == 1].copy()\n",
    "frankshu_hate['label'] = 0\n",
    "\n",
    "frankshu_normal = frankshu[frankshu['label'] == 0].copy()\n",
    "frankshu_normal['label'] = 2\n",
    "\n",
    "frankshu = pd.concat([frankshu_hate, frankshu_normal])\n",
    "\n",
    "frankshu = frankshu.drop(columns=['categories'])\n",
    "frankshu = frankshu.rename(columns={\"tweet\": \"text\"})\n",
    "frankshu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frankshu = load_dataset(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([hate_explain, davidson_df, gab, frankshu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95342e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782dd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.iloc[:10]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627bbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/processed_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12041cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adface",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
